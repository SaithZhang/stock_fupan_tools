import pandas as pd
import os
import shutil
import sys
import re
from datetime import datetime
from colorama import init, Fore

# --- å¯¼å…¥ä¿®å¤ ---
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    from .data_loader import get_merged_data
except ImportError:
    from data_loader import get_merged_data
# --------------

init(autoreset=True)

# ================= 1. è·¯å¾„ä¸é…ç½® =================

PROJECT_ROOT = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(PROJECT_ROOT) # Fix import src issue

OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'data', 'output')
ARCHIVE_DIR = os.path.join(OUTPUT_DIR, 'archive')

HOLDINGS_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'holdings.txt')
F_LAO_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'f_lao_list.txt')

# --- ç­–ç•¥é…ç½® (ä¸ akshare ç‰ˆä¿æŒä¸€è‡´) ---
CORE_KEYWORDS = [
    'æœºå™¨äºº', 'èˆªå¤©', 'å†›å·¥', 'å«æ˜Ÿ', 'ä½ç©º',
    'AI', 'äººå·¥æ™ºèƒ½', 'æ™ºèƒ½ä½“', 'ç®—åŠ›', 'CPO', 'å­˜å‚¨',
    'æ¶ˆè´¹ç”µå­', 'åä¸º', 'ä¿¡åˆ›', 'æ•°å­—è´§å¸', 'æ•°æ®è¦ç´ ',
    'æ–‡åŒ–ä¼ åª’', 'çŸ­å‰§', 'å¤šæ¨¡æ€', 'çººç»‡', 'å¹¶è´­é‡ç»„', 'å›ºæ€ç”µæ± ', 'è‡ªåŠ¨é©¾é©¶'
]

# æŒä»“è‚¡ç‰¹æ®Šç­–ç•¥é…ç½® (ä»£ç : (æ ‡ç­¾, è”åŠ¨å¤§å“¥ä»£ç ))
HOLDING_STRATEGIES = {
}

# è”åŠ¨å¤§å“¥æ˜ å°„ (å°å¼Ÿä»£ç : å¤§å“¥ä»£ç )
LINK_DRAGON_MAP = {
    '002009': '002931',
}


# ================= 2. è¾…åŠ©å‡½æ•° =================

def load_text_list(filepath):
    """åŠ è½½å…³æ³¨åˆ—è¡¨/æŒä»“åˆ—è¡¨"""
    if not os.path.exists(filepath): return {}
    mapping = {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'): continue
                parts = re.split(r'\s+', line, maxsplit=1)
                code = parts[0].strip()
                # ç®€å•æ¸…æ´—ä»£ç 
                code = code.replace("SZ", "").replace("SH", "")
                if code.isdigit() and len(code) == 6:
                    tag = parts[1].strip() if len(parts) > 1 else "å…³æ³¨"
                    mapping[code] = tag
    except Exception as e:
        print(f"{Fore.RED}åŠ è½½åˆ—è¡¨å¤±è´¥ {filepath}: {e}")
    return mapping


def load_yesterday_pool():
    """
    åŠ è½½æœ€è¿‘ä¸€æœŸçš„ç­–ç•¥æ± æ–‡ä»¶ (ä¸å«ä»Šæ—¥)
    ç›®çš„æ˜¯å¯»æ‰¾æ˜¨æ—¥ç‚¸æ¿çš„è‚¡ç¥¨
    è¿”å›: {code: {'amount': float, 'tag': str}}
    """
    if not os.path.exists(OUTPUT_DIR): return {}
    
    # 1. æŸ¥æ‰¾æ‰€æœ‰ strategy_pool_YYYYMMDD.csv
    files = []
    today_str = datetime.now().strftime("%Y%m%d")
    
    for f in os.listdir(OUTPUT_DIR):
        if f.startswith('strategy_pool_') and f.endswith('.csv'):
            date_part = f.replace('strategy_pool_', '').replace('.csv', '')
            if date_part.isdigit() and date_part < today_str:
                files.append({'path': os.path.join(OUTPUT_DIR, f), 'date': date_part})
                
    if not files:
        # å°è¯• archive ç›®å½•
        if os.path.exists(ARCHIVE_DIR):
            for f in os.listdir(ARCHIVE_DIR):
                if f.startswith('strategy_pool_') and f.endswith('.csv'):
                    date_part = f.replace('strategy_pool_', '').replace('.csv', '')
                    if date_part.isdigit() and date_part < today_str:
                        files.append({'path': os.path.join(ARCHIVE_DIR, f), 'date': date_part})

    if not files:
        print(f"{Fore.YELLOW}âš ï¸ æœªæ‰¾åˆ°æ˜¨æ—¥(æˆ–æ›´æ—©)çš„ç­–ç•¥æ± æ–‡ä»¶ï¼Œæ— æ³•æ‰§è¡Œ[æ–­æ¿ååŒ…]ç­–ç•¥")
        return {}
        
    # 2. æ’åºå–æœ€æ–°çš„ä¸€ä¸ª
    files.sort(key=lambda x: x['date'], reverse=True)
    target_file = files[0]['path']
    print(f"{Fore.BLUE}ğŸ”™ å›æº¯å†å²æ•°æ®: {os.path.basename(target_file)}")
    
    res_map = {}
    try:
        df = pd.read_csv(target_file, dtype={'code': str, 'sina_code': str})
        # å¿…é¡»åˆ—: code, tag, amount
        for _, row in df.iterrows():
            c = str(row['code']).zfill(6)
            tag = str(row.get('tag', ''))
            
            # ç­›é€‰æ˜¨æ—¥ç‚¸æ¿è‚¡ (tagä¸­åŒ…å«"ç‚¸æ¿")
            # æ³¨æ„ï¼šæ˜¨æ—¥å¿…é¡»æ˜¯çœŸçš„ç‚¸æ¿äº†ï¼Œè€Œä¸æ˜¯"ååŒ…é¢„æœŸ"è¿™ç§
            # ç®€å•åˆ¤æ–­: åªè¦ tag é‡Œæœ‰ "ç‚¸æ¿" å­—æ ·ï¼Œå°±çº³å…¥è§‚å¯Ÿæ± 
            if "ç‚¸æ¿" in tag:
                res_map[c] = {
                    'amount': float(row.get('amount', 0)),
                    'tag': tag
                }
    except Exception as e:
        print(f"{Fore.RED}âŒ è¯»å–å†å²æ–‡ä»¶å¤±è´¥: {e}")
        
    return res_map


def load_lhb_info():
    """
    åŠ è½½é¾™è™æ¦œæ•°æ® & æ¸¸èµ„æ•°æ®
    Returns:
       lhb_codes: set of codes (str 6 digits)
       seat_map: {stock_name: [tags]}
    """
    lhb_dir = os.path.join(PROJECT_ROOT, 'data', 'output', 'lhb')
    lhb_path = os.path.join(lhb_dir, 'lhb_latest.csv')
    seat_path = os.path.join(lhb_dir, 'lhb_famous_latest.csv')
    
    lhb_codes = set()
    if os.path.exists(lhb_path):
        try:
             df = pd.read_csv(lhb_path, dtype=str)
             # åŒæ ·æ¸…æ´—ä¸‹ input
             if 'ä»£ç ' in df.columns:
                 # ç¡®ä¿æ˜¯6ä½
                 lhb_codes = set(df['ä»£ç '].apply(lambda x: str(x).strip().zfill(6)).tolist())
        except Exception as e:
            print(f"{Fore.RED}âŒ LHBåŠ è½½å¤±è´¥: {e}")

    seat_map = {}
    if os.path.exists(seat_path):
         try:
             df = pd.read_csv(seat_path, dtype=str)
             import re
             
             # Columns: æ¸¸èµ„æ ‡ç­¾, è¥ä¸šéƒ¨åç§°, ä¹°å…¥è‚¡ç¥¨, å–å‡ºè‚¡ç¥¨...
             for _, row in df.iterrows():
                 label = row['æ¸¸èµ„æ ‡ç­¾']
                 
                 # 1. å¤„ç†ä¹°å…¥
                 buys = str(row.get('ä¹°å…¥è‚¡ç¥¨', '')).replace('nan', '')
                 stock_names_b = re.split(r'[ ,ã€]+', buys)
                 for s in stock_names_b:
                     s = s.strip()
                     if not s: continue
                     if s not in seat_map: seat_map[s] = set()
                     seat_map[s].add(f"ğŸ’°{label}å…¥åœº")
                     
                 # 2. å¤„ç†å–å‡º
                 sells = str(row.get('å–å‡ºè‚¡ç¥¨', '')).replace('nan', '')
                 stock_names_s = re.split(r'[ ,ã€]+', sells)
                 for s in stock_names_s:
                     s = s.strip()
                     if not s: continue
                     if s not in seat_map: seat_map[s] = set()
                     seat_map[s].add(f"ğŸƒ{label}ç¦»åœº")
                     
         except Exception as e:
            print(f"{Fore.RED}âŒ æ¸¸èµ„æ•°æ®åŠ è½½å¤±è´¥: {e}")
            
    return lhb_codes, seat_map



def format_sina(code):
    code = str(code)
    if code.startswith('6'): return f"sh{code}"
    if code.startswith('8') or code.startswith('4'): return f"bj{code}"
    return f"sz{code}"


def get_link_dragon(code):
    """è·å–å…³è”çš„å¤§å“¥ä»£ç """
    if code in HOLDING_STRATEGIES:
        dragon = HOLDING_STRATEGIES[code][1]
        if dragon: return dragon

    dragon = LINK_DRAGON_MAP.get(code, '')
    if dragon:
        if dragon.startswith('sz') or dragon.startswith('sh'): return dragon
        return format_sina(dragon)
    return ''


def clean_manual_tag(tag, is_zt_tag_present):
    """
    æ¸…æ´—æ‰‹åŠ¨æ ‡ç­¾ï¼Œé¿å…å†—ä½™
    1. å»é™¤é‡å¤çš„ 'Fä½¬' å‰ç¼€
    2. å¦‚æœæœ‰å®æ—¶æ¶¨åœæ•°æ®ï¼Œå°è¯•ç§»é™¤æ‰‹åŠ¨å¤‡æ³¨ä¸­è¿‡æ—¶çš„ '3æ¿' ç­‰å­—æ ·
    """
    if not tag: return ""

    # 1. æ¸…ç†é‡å¤å‰ç¼€ (å¦‚ "Fä½¬/Fä½¬/...")
    if tag.startswith("Fä½¬/"):
        tag = tag[3:]
    elif tag.startswith("Fä½¬"):
        tag = tag.lstrip("Fä½¬").lstrip("/")

    # 2. æ¸…ç†è¿‡æ—¶è¿æ¿ä¿¡æ¯ (e.g. å¤‡æ³¨æ˜¯3æ¿ï¼Œä½†ä»Šå¤©å®é™…ä¸Š4æ¿äº†)
    if is_zt_tag_present:
        # æ­£åˆ™æ›¿æ¢ï¼šåŒ¹é… "3æ¿", "2è¿æ¿" ç­‰ï¼Œä¸”å‰åæœ‰åˆ†éš”ç¬¦æˆ–è¾¹ç•Œ
        # å…¼å®¹ "é›·ç§‘(3æ¿/å†›å·¥)" è¿™ç§æ‹¬å·å†…çš„å†™æ³•
        tag = re.sub(r'(^|/|[(])\d+æ¿([)]|/|$)', r'\1\2', tag)

        # æ¸…ç†æ­£åˆ™æ›¿æ¢åç•™ä¸‹çš„æ®‹ç•™ç¬¦å· (å¦‚ "//", "()")
        tag = tag.replace('()', '').replace('//', '/').replace('(/', '(').replace('/)', ')')
        tag = tag.strip('/')

    return tag


def get_unique_concepts(base_str, new_concepts_str):
    """
    ä»…è¿”å› base_str (æ‰‹åŠ¨å¤‡æ³¨) ä¸­ä¸å­˜åœ¨çš„æ–°æ¦‚å¿µ
    é¿å…å‡ºç° "é›·ç§‘(å†›å·¥)/.../å†›å·¥" è¿™ç§é‡å¤
    """
    if not new_concepts_str: return ""

    # å°† base_str æ‹†è§£ä¸ºå…³é”®è¯é›†åˆ (æŒ‰ / å’Œ æ‹¬å· æ‹†åˆ†)
    base_parts = re.split(r'[/()]', base_str)
    base_set = set(p.strip() for p in base_parts if p.strip())

    new_parts = new_concepts_str.split('/')
    final_new = []
    for c in new_parts:
        c = c.strip()
        # å¦‚æœæ–°æ¦‚å¿µä¸åœ¨å·²æœ‰é›†åˆä¸­ï¼Œä¸”ä¸æ˜¯å·²æœ‰å­—ç¬¦ä¸²çš„å­ä¸² (é˜²æ­¢ "å†›å·¥" vs "å†›å·¥æ¿å—" é‡å¤)
        if c and c not in base_set and c not in base_str:
            final_new.append(c)

    return "/".join(final_new)


def get_core_concepts_local(name, raw_tag):
    """æœ¬åœ°æå–æ ¸å¿ƒæ¦‚å¿µ"""
    matched = set()
    source_text = f"{name} {raw_tag}"

    for key in CORE_KEYWORDS:
        if key in source_text:
            matched.add(key)

    return "/".join(list(matched))


def check_special_shape(item):
    """æ£€æŸ¥ç‰¹æ®Šå½¢æ€ (åœ°å¤©æ¿/20cm/èµ„é‡‘é¢)"""
    tags = []
    pct = item.get('today_pct', 0)
    low_pct = 0
    if 'low' in item and 'prev_close' in item and item['prev_close'] > 0:
        low_pct = (item['low'] - item['prev_close']) / item['prev_close'] * 100

    if low_pct < -9.0 and pct > 9.0: tags.append("ğŸ”¥åœ°å¤©æ¿")
    if pct > 14.0: tags.append("ğŸ”¥20cm")

    amount_val = item.get('amount', 0)
    amt_yi = amount_val / 100000000.0

    if amt_yi > 20.0:
        tags.append("ğŸ’°å¤§æˆ˜åœº")
    elif amt_yi < 0.5 and amt_yi > 0:
        tags.append("âš ï¸æµåŠ¨æ€§å·®")

    return tags


# ================= 3. ä¸»ç”Ÿæˆé€»è¾‘ =================

def generate_strategy_pool():
    all_data = get_merged_data()
    if not all_data:
        print(f"{Fore.RED}âŒ æ•°æ®æºä¸ºç©ºï¼Œè¯·æ£€æŸ¥ data_loader")
        return

    holdings_map = load_text_list(HOLDINGS_PATH)
    f_lao_map = load_text_list(F_LAO_PATH)
    
    # --- è¾¨è¯†åº¦/äººæ°”æ ‡çš„åŠ è½½ ---
    MANUAL_FOCUS_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'manual_focus.txt')
    manual_recognition_map = load_text_list(MANUAL_FOCUS_PATH)

    # --- æ˜¨æ—¥ç‚¸æ¿æ•°æ®åŠ è½½ (æ–°ç­–ç•¥) ---
    broken_pool_map = load_yesterday_pool()
    
    # --- é¾™è™æ¦œ/æ¸¸èµ„æ•°æ®åŠ è½½ (æ–°ç­–ç•¥) ---
    lhb_codes, lhb_seat_map = load_lhb_info()

    # åˆå¹¶åŸºæœ¬å…³æ³¨ï¼ˆFä½¬ + æŒä»“ï¼‰
    base_focus = f_lao_map.copy()
    base_focus.update(holdings_map)

    print(f"{Fore.CYAN}ğŸ“‹ ç¦»çº¿ç”Ÿæˆå¯åŠ¨ | æ•°æ®æº: {len(all_data)}æ¡ | æŒä»“: {len(holdings_map)} | å…³æ³¨: {len(f_lao_map)} | LHB: {len(lhb_codes)}")

    pool = []

    for item in all_data:
        code = str(item['code'])
        name = item['name']
        pct = item.get('today_pct', 0)

        raw_tag_str = str(item.get('tag', ''))
        if 'nan' in raw_tag_str: raw_tag_str = ""
        
        # --- 0. å…¨å±€è¿‡æ»¤: å‰”é™¤ ST è‚¡ ---
        if 'ST' in name.upper():
            continue

        base_tags = []
        is_selected = False
        has_zt_status = False  # æ˜¯å¦æœ‰æ¶¨åœçŠ¶æ€

        # --- 1. æ¶¨åœçŠ¶æ€é¢„åˆ¤ ---
        # å…ˆåˆ¤æ–­æ¶¨åœï¼Œæ–¹ä¾¿åç»­æ¸…æ´—æ‰‹åŠ¨æ ‡ç­¾æ—¶çŸ¥é“æ˜¯å¦è¦ç§»é™¤æ—§æ¿æ•°
        is_zt = item.get('is_zt') or (pct >= 9.8)
        zt_tag = ""
        if is_zt:
            has_zt_status = True
            limit_days = item.get('limit_days', 0)
            zt_tag = f"{limit_days}æ¿" if limit_days > 0 else "é¦–æ¿"
            open_num = item.get('open_num', 0)
            if open_num > 0:
                zt_tag += f"/å›å°(ç‚¸{open_num}æ¬¡)"
            elif item.get('is_first_limit'):
                zt_tag += "/ç¡¬æ¿"

        # --- 2. èº«ä»½åˆ¤å®š (æŒä»“/å…³æ³¨) ---
        manual_cleaned_tag = ""
        if code in base_focus:
            is_selected = True
            if code in HOLDING_STRATEGIES:
                # ç‰¹æ®Šç­–ç•¥ï¼Œç›´æ¥ä½¿ç”¨
                base_tags.append(HOLDING_STRATEGIES[code][0])
                manual_cleaned_tag = HOLDING_STRATEGIES[code][0]  # è®°å½•ä¸‹æ¥ç”¨äºå»é‡
            elif code in holdings_map:
                t = f"æŒä»“/{name}"
                base_tags.append(t)
                manual_cleaned_tag = t
            else:
                # Fä½¬å…³æ³¨ - è¿›è¡Œæ·±åº¦æ¸…æ´—
                raw_note = f_lao_map[code]
                cleaned_note = clean_manual_tag(raw_note, has_zt_status)

                # é‡æ–°ç»„è£…
                final_manual = f"Fä½¬/{cleaned_note}" if cleaned_note != "å…³æ³¨" else "Fä½¬/å…³æ³¨"
                base_tags.append(final_manual)
                manual_cleaned_tag = final_manual
                
        # --- 2.1 é¾™è™æ¦œ & æ¸¸èµ„åˆ¤å®š (æ–°å¢) ---
        if code in lhb_codes:
            is_selected = True
            base_tags.append("ğŸ‰é¾™è™æ¦œ")
        
        if name in lhb_seat_map:
            is_selected = True
            # æ·»åŠ æ¸¸èµ„æ ‡ç­¾ (å·²å»é‡)
            seat_tags = sorted(list(lhb_seat_map[name]))
            base_tags.extend(seat_tags)
        
        # --- 2.5 è¾¨è¯†åº¦/äººæ°”åˆ¤å®š (æ–°å¢) ---
        is_popular = False
        pop_reasons = set()
        
        # A. æ‰‹åŠ¨ç»´æŠ¤çš„äººæ°”è‚¡
        if code in manual_recognition_map or name in manual_recognition_map:
            is_popular = True
            
        # B. è‡ªåŠ¨åˆ¤å®šï¼š3è¿æ¿ä»¥ä¸Šé«˜æ ‡
        limit_days = item.get('limit_days', 0)
        if limit_days >= 3:
            is_popular = True
            # æ¿æ•°åé¢ä¼šè‡ªåŠ¨åŠ ï¼Œè¿™é‡Œä¸é‡å¤åŠ 
            
        # C. è‡ªåŠ¨åˆ¤å®šï¼šå¤§æˆäº¤é¢å‰æ’ (>=20äº¿)
        amount_val = item.get('amount', 0)
        if amount_val >= 20_0000_0000: # 20äº¿
            is_popular = True
            pop_reasons.add("æˆäº¤") 
        
        if is_popular:
            is_selected = True
            base_tags.append("â˜…äººæ°”")
            if pop_reasons:
                base_tags.extend(sorted(list(pop_reasons)))

        # --- 2.6 æ–­æ¿ååŒ… (æ–°ç­–ç•¥) ---
        # é€»è¾‘ï¼šæ˜¨æ—¥åœ¨ç‚¸æ¿æ±  + ä»Šæ—¥æ”¶çº¢ (æœ€å¥½çˆ†é‡)
        if code in broken_pool_map:
            # åªè¦æ˜¯çº¢ç›˜ï¼Œå°±çº³å…¥
            if pct > 0:
                is_selected = True
                
                # è®¡ç®—æ˜¯å¦çˆ†é‡
                yest_amt = broken_pool_map[code]['amount']
                curr_amt = item.get('amount', 0)
                
                label = "ğŸ”¥ç„šè¯€"
                if yest_amt > 10000 and curr_amt > yest_amt: # ç®€å•åˆ¤æ–­æˆäº¤é¢å¢åŠ 
                     label += "/çˆ†é‡"
                
                base_tags.append(label)

        # --- 3. æ ‡ç­¾ç»„è£… ---

        # æ¶¨åœæ ‡ç­¾
        if is_zt:
            is_selected = True
            base_tags.append(zt_tag)

        # ç‚¸æ¿
        is_zb = False
        if "ç‚¸æ¿" in raw_tag_str:
            is_zb = True
        elif item.get('max_pct', 0) > 9.0 and pct < 9.0:
            is_zb = True

        if is_zb and pct > -7.0:
            is_selected = True
            base_tags.append("ğŸ‘€ç„šè¯€é¢„æœŸ/ç‚¸æ¿")

        # è·Œåœ
        if pct <= -9.0:
            is_selected = True
            base_tags.append("ğŸ“‰è·Œåœ/åšå¼ˆä¿®å¤")

        # å¤§é¢æˆäº¤ (è¡¥å½•)
        amount_yi = item.get('amount', 0) / 100000000.0
        if amount_yi > 20.0 and pct > 0:
            is_selected = True

        # --- 4. æœ€ç»ˆåˆå¹¶ ---
        if is_selected:
            # æå–æ¦‚å¿µ (å¹¶å»é‡)
            local_concepts = get_core_concepts_local(name, raw_tag_str)
            # å…³é”®ï¼šä»è‡ªåŠ¨æ¦‚å¿µä¸­å‰”é™¤å·²ç»åœ¨æ‰‹åŠ¨æ ‡ç­¾é‡Œå‡ºç°è¿‡çš„è¯
            unique_concepts = get_unique_concepts(manual_cleaned_tag, local_concepts)

            # ç‰¹æ®Šå½¢æ€
            shape_tags = check_special_shape(item)

            # åˆå¹¶åˆ—è¡¨
            final_parts = []
            final_parts.extend(base_tags)
            if unique_concepts: final_parts.append(unique_concepts)
            final_parts.extend(shape_tags)

            # ç®€å•å»é‡ (é˜²æ­¢å®Œå…¨ä¸€æ ·çš„å­—ç¬¦ä¸²é‡å¤)
            seen_parts = set()
            clean_parts = []
            for p in final_parts:
                if p not in seen_parts:
                    clean_parts.append(p)
                    seen_parts.add(p)

            final_tag_str = "/".join(clean_parts)

            # å†æ¬¡æ¸…ç†å¯èƒ½äº§ç”Ÿçš„åŒæ–œæ 
            final_tag_str = final_tag_str.replace('//', '/')
            
            # --- æœ€ç»ˆ Tag ä¿®æ­£: ç¡®ä¿ ç„šè¯€ å…³é”®å­—æ˜¾çœ¼ ---
            # å¦‚æœæ˜¯ æ–­æ¿ååŒ… (å·²åœ¨ base_tags é‡Œå¤„ç†äº†ï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œå¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€æ›¿æ¢)
            final_tag_str = final_tag_str.replace("ğŸ”¥æ–­æ¿ååŒ…", "ğŸ”¥ç„šè¯€")
            
            row = {
                'sina_code': format_sina(code),
                'name': name,
                'tag': final_tag_str,
                'amount': item.get('amount', 0),
                'today_pct': pct,
                'turnover': item.get('turnover', 0),
                'open_pct': item.get('open_pct', 0),
                'price': item.get('price', 0),
                'pct_10': item.get('pct_10', 0),
                'link_dragon': get_link_dragon(code),
                'vol': item.get('vol', 0),
                'vol_prev': item.get('vol_prev', 0),
                'vol_ratio': item.get('vol_ratio', 0),
                'code': code
            }
            pool.append(row)

    # --- 4.5 å¼‚åŠ¨é£é™©è®¡ç®— (æ”¹ä¸ºè¯»å–æ‰‹åŠ¨æ–‡ä»¶) ---
    print(f"{Fore.MAGENTA}ğŸ” æ­£åœ¨åŠ è½½å¼‚åŠ¨é£é™©æ•°æ® (æ‰‹åŠ¨æ–‡ä»¶)...")
    try:
        # 1. å¯»æ‰¾æœ€æ–°çš„ risk_YYYYMMDD.csv
        input_dir = os.path.join(PROJECT_ROOT, 'data', 'input', 'risk')
        if not os.path.exists(input_dir):
            print(f"   âš ï¸ æœªæ‰¾åˆ°é£é™©æ–‡ä»¶å¤¹: {input_dir}")
            risk_files = []
        else:
            risk_files = [f for f in os.listdir(input_dir) if f.startswith('risk_') and f.endswith('.csv')]
        
        target_risk_file = None
        if risk_files:
            # Sort by date in filename risk_20260107.csv
            risk_files.sort(reverse=True)
            target_risk_file = os.path.join(input_dir, risk_files[0])
            print(f"   ğŸ“„ æ‰¾åˆ°æ–‡ä»¶: {risk_files[0]}")
        
        risk_map = {}
        if target_risk_file:
            try:
                # pandas read
                risk_df = pd.read_csv(target_risk_file)
                # Ensure columns exist
                # Expected: è‚¡ç¥¨åç§°,ç›‘ç®¡è§„åˆ™,å½“å‰ç´¯è®¡åç¦»å€¼,å¼‚åŠ¨è§¦å‘æ¡ä»¶,é£é™©ç­‰çº§,æ•°æ®æ—¥æœŸ
                # Map to: risk_level, risk_msg, trigger_next, risk_rule
                for _, row in risk_df.iterrows():
                    name = str(row['è‚¡ç¥¨åç§°']).strip()
                    risk_map[name] = {
                        'risk_level': str(row.get('é£é™©ç­‰çº§', 'ğŸŸ¢ Safe')),
                        'risk_msg': str(row.get('å½“å‰ç´¯è®¡åç¦»å€¼', '')),
                        'risk_rule': str(row.get('ç›‘ç®¡è§„åˆ™', '')),
                        'trigger_next': str(row.get('å¼‚åŠ¨è§¦å‘æ¡ä»¶', ''))
                    }
            except Exception as e:
                print(f"{Fore.RED}âš ï¸ è¯»å–CSVå¤±è´¥: {e}")

        # 2. åˆå¹¶åˆ° pool
        matches = 0
        for p in pool:
            name = p['name']
            if name in risk_map:
                info = risk_map[name]
                p['risk_level'] = info['risk_level']
                p['risk_msg'] = info['risk_msg']
                p['risk_rule'] = info['risk_rule']
                p['trigger_next'] = info['trigger_next']
                matches += 1
            else:
                # Default safe
                p['risk_level'] = 'ğŸŸ¢ Safe'
                p['risk_msg'] = '-'
                p['trigger_next'] = '-'
                
        print(f"   âœ… æˆåŠŸåŒ¹é… {matches} åªæ ‡çš„é£é™©æ•°æ®")
        
    except Exception as e:
        print(f"{Fore.RED}âš ï¸ é£é™©æ•°æ®åŠ è½½å¼‚å¸¸: {e}")

    # --- 5. å¯¼å‡º ---
    if pool:
        df = pd.DataFrame(pool)
        df.sort_values(by='amount', ascending=False, inplace=True)

        cols = ['sina_code', 'name', 'tag', 'amount', 'today_pct', 'turnover', 'open_pct', 'price', 
                'risk_level', 'risk_msg', 'trigger_next', 'risk_rule', # æ–°å¢åˆ—
                'pct_10', 'link_dragon', 'vol', 'vol_prev', 'vol_ratio', 'code']
        for c in cols:
            if c not in df.columns: df[c] = 0
        df = df[cols]

        date_str = datetime.now().strftime("%Y%m%d")
        
        # æ”¹åŠ¨ï¼šç›´æ¥åœ¨ output ç›®å½•ç”Ÿæˆå¸¦æ—¥æœŸçš„æ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥çœ‹
        dated_filename = f'strategy_pool_{date_str}.csv'
        dated_path = os.path.join(OUTPUT_DIR, dated_filename)
        latest_path = os.path.join(OUTPUT_DIR, 'strategy_pool.csv')

        df.to_csv(dated_path, index=False, encoding='utf-8-sig')
        
        # åŒæ—¶å¤åˆ¶ä¸€ä»½ä¸ºé€šç”¨åï¼Œä¾›å…¶ä»–è„šæœ¬è¯»å–
        shutil.copyfile(dated_path, latest_path)

        print(f"\n{Fore.GREEN}ğŸ‰ ç¦»çº¿å¤ç›˜å®Œæˆï¼ç”Ÿæˆæ ‡çš„: {len(pool)} åª")
        print(f"ğŸ“„ æ—¥æœŸæ–‡ä»¶: {dated_path}")
        print(f"ğŸ“„ é€šç”¨æ–‡ä»¶: {latest_path} (å·²æ›´æ–°)")

    else:
        print(f"{Fore.RED}âŒ ç­›é€‰ç»“æœä¸ºç©ºã€‚")


if __name__ == "__main__":
    generate_strategy_pool()