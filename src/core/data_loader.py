import pandas as pd
import akshare as ak
import os
import re
import glob
from colorama import init, Fore

init(autoreset=True)

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
TDX_DIR = os.path.join(PROJECT_ROOT, 'data', 'input', 'tdx')
THS_DIR = os.path.join(PROJECT_ROOT, 'data', 'input', 'ths')


def clean_code(code_str):
    return re.sub(r'\D', '', str(code_str))


def find_latest_file(directory, extensions=[".txt", ".csv", ".xlsx", ".xls"]):
    if not os.path.exists(directory): return None
    candidates = []
    for ext in extensions:
        candidates.extend(glob.glob(os.path.join(directory, f"*{ext}")))
    if not candidates: return None
    return max(candidates, key=os.path.getmtime)


def safe_float(val):
    if pd.isna(val): return 0.0
    s = str(val).strip()
    if s == '--' or s == '' or s.lower() == 'nan': return 0.0
    if '%' in s: s = s.replace('%', '')
    s = s.replace(',', '')
    # å¤„ç†ä¸­æ–‡å•ä½
    unit = 1.0
    if 'äº¿' in s:
        s = s.replace('äº¿', '')
        unit = 100000000.0
    elif 'ä¸‡' in s:
        s = s.replace('ä¸‡', '')
        unit = 10000.0
    try:
        f = float(s) * unit
        return f
    except:
        return 0.0


def safe_str(val):
    if pd.isna(val): return ""
    s = str(val).strip()
    if s.lower() == 'nan' or s == '--': return ""
    return s


# ================= 1. åŠ è½½åŒèŠ±é¡º (ä¿®å¤ç‰ˆ) =================
def load_ths_data():
    # æ”¹è¿›çš„æ–‡ä»¶æŸ¥æ‰¾é€»è¾‘ï¼šä¼˜å…ˆæ‰¾æ–‡ä»¶åå¸¦æ—¥æœŸçš„æœ€æ–°æ–‡ä»¶
    # æ”¯æŒæ ¼å¼: Table-20260117.txt, Table_20260117.txt
    if not os.path.exists(THS_DIR): return {}
    
    files = os.listdir(THS_DIR)
    candidates = []
    
    for f in files:
        if f.startswith("Table") and f.endswith(".txt"):
            full_path = os.path.join(THS_DIR, f)
            # å°è¯•æå–æ—¥æœŸ (æ”¯æŒ - æˆ– _)
            date_match = re.search(r'[-_]?(20\d{6})', f)
            date_int = int(date_match.group(1)) if date_match else 0
            
            # Table.txt è§†ä¸ºæ— æ—¥æœŸ(0) æˆ– æå¤§(99999999) æ ¹æ®ç­–ç•¥
            # è¿™é‡Œç­–ç•¥ï¼šå¦‚æœæœ‰å¸¦æ—¥æœŸçš„ï¼Œå–æ—¥æœŸæœ€å¤§çš„ï¼›å¦‚æœæ²¡æœ‰ï¼Œå–æœ€è¿‘ä¿®æ”¹çš„ Table.txt
            if f == "Table.txt":
                 candidates.append({'path': full_path, 'date': 0, 'mtime': os.path.getmtime(full_path)})
            else:
                 candidates.append({'path': full_path, 'date': date_int, 'mtime': 0})
    
    target_file = None
    if candidates:
        # 1. ä¼˜å…ˆæŒ‰æ–‡ä»¶åé‡Œçš„æ—¥æœŸæ’åº
        dated = [c for c in candidates if c['date'] > 0]
        if dated:
            dated.sort(key=lambda x: x['date'], reverse=True)
            target_file = dated[0]['path']
        else:
            # 2. å¦åˆ™æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            candidates.sort(key=lambda x: x['mtime'], reverse=True)
            target_file = candidates[0]['path']
            
    if not target_file: return {}

    if not target_file: return {}

    print(f"{Fore.BLUE}ğŸ“‚ [ä¼˜å…ˆ] åŠ è½½åŒèŠ±é¡ºæ•°æ®: {os.path.basename(target_file)}")
    return _parse_ths_csv(target_file)


def load_yesterday_ths_data():
    """
    åŠ è½½æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥(ä¸å«ä»Šæ—¥)çš„æ•°æ®ï¼Œç”¨äºè®¡ç®—æ˜¨æ—¥æ¶¨åœæº¢ä»·ã€æ˜¨æ—¥é‡æ¯”ç­‰
    """
    # 1. å…ˆæ‰¾åˆ°ä»Šå¤©çš„æ—¥æœŸ (ä»æœ€æ–°çš„æ–‡ä»¶åé‡Œæå–)
    if not os.path.exists(THS_DIR): return {}
    files = os.listdir(THS_DIR)
    latest_date = 0
    for f in files:
        if f.startswith("Table") and f.endswith(".txt"):
             date_match = re.search(r'[-_]?(20\d{6})', f)
             if date_match:
                 d = int(date_match.group(1))
                 if d > latest_date: latest_date = d
    
    if latest_date == 0: return {}
    
    # 2. æ‰¾ä¸Šä¸€ä¸ªæ–‡ä»¶
    prev_file_path = find_previous_ths_file(latest_date)
    if not prev_file_path:
        print(f"{Fore.YELLOW}âš ï¸ æœªæ‰¾åˆ°æ˜¨æ—¥THSæ•°æ®æ–‡ä»¶")
        return {}
        
    print(f"{Fore.BLUE}ğŸ”™ åŠ è½½æ˜¨æ—¥åŒèŠ±é¡ºæ•°æ®: {os.path.basename(prev_file_path)}")
    return _parse_ths_csv(prev_file_path)


def _parse_ths_csv(target_file):
    try:
        # --- å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨æ­£åˆ™åˆ†éš”ç¬¦å¤„ç†ä¸è§„åˆ™çš„ tab ---
        # sep=r'\t+' è¡¨ç¤ºæŠŠè¿ç»­çš„ tab å½“ä½œä¸€ä¸ªåˆ†éš”ç¬¦
        try:
            df = pd.read_csv(target_file, sep=r'\t+', engine='python', encoding='gbk', dtype=str)
        except:
            try:
                df = pd.read_csv(target_file, sep=r'\t+', engine='python', encoding='utf-16', dtype=str)
            except:
                df = pd.read_csv(target_file, sep=r'\t+', engine='python', encoding='utf-8', dtype=str)

        df.columns = [c.strip() for c in df.columns]

        # æ‰“å°å‰å‡ åˆ—åï¼Œç”¨äºè°ƒè¯•
        # print(f"   (Debug) è§£æåˆ—å: {df.columns.tolist()[:5]}...")

        data_map = {}

        col_code = next((c for c in df.columns if 'ä»£ç ' in c), None)
        col_name = next((c for c in df.columns if 'åç§°' in c), None)
        col_price = next((c for c in df.columns if 'ç°ä»·' in c), None)
        col_pct = next((c for c in df.columns if 'æ¶¨å¹…' in c and 'ç«ä»·' not in c and '10' not in c and '3' not in c), None)
        col_amt = next((c for c in df.columns if 'æˆäº¤é¢' in c and '3æ—¥' not in c and '5æ—¥' not in c), None)
        col_to = next((c for c in df.columns if 'æ¢æ‰‹' in c), None)

        col_zt_days = next((c for c in df.columns if 'è¿ç»­æ¶¨åœ' in c or 'è¿æ¿' in c), None)
        col_reason = next((c for c in df.columns if 'åŸå› ' in c), None)
        col_desc = next((c for c in df.columns if 'å‡ å¤©å‡ æ¿' in c), None)
        col_pct10 = next((c for c in df.columns if '10æ—¥æ¶¨å¹…' in c), None)
        col_auc_pct = next((c for c in df.columns if 'ç«ä»·æ¶¨å¹…' in c), None)
        
        # --- New Columns ---
        col_auc_amt = next((c for c in df.columns if 'æ—©ç›˜ç«ä»·é‡‘é¢' in c), None)
        col_open_num = next((c for c in df.columns if 'å¼€æ¿æ¬¡æ•°' in c), None)
        col_industry = next((c for c in df.columns if 'æ‰€å±è¡Œä¸š' in c), None)
        col_pct20 = next((c for c in df.columns if '20æ—¥æ¶¨å¹…' in c), None)

        if not col_code:
            print(f"{Fore.RED}âŒ è§£æå¤±è´¥ï¼šæœªæ‰¾åˆ°ã€ä»£ç ã€‘åˆ—ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶æ ¼å¼å¤ªä¹±ã€‚")
            return {}

        for _, row in df.iterrows():
            code = clean_code(row[col_code])
            if len(code) != 6: continue

            # åŸºç¡€æ•°æ®
            name = safe_str(row.get(col_name))
            price = safe_float(row.get(col_price))
            pct = safe_float(row.get(col_pct))

            # --- æ ¡éªŒï¼šé˜²æ­¢é”™ä½ (å¦‚æŠŠä»·æ ¼å½“æˆæ¶¨å¹…) ---
            if abs(pct) > 60 and 'N' not in name and 'C' not in name:
                pct = 0.0
            if '%' in name or len(name) > 10:
                continue

            item = {
                'source': 'THS',
                'code': code,
                'name': name,
                'price': price,
                'today_pct': pct,
                'amount': safe_float(row.get(col_amt)),
                'turnover': safe_float(row.get(col_to)),
                'pct_10': safe_float(row.get(col_pct10)),
                'open_pct': safe_float(row.get(col_auc_pct)),
                
                # New Fields
                'call_auction_amount': safe_float(row.get(col_auc_amt)),
                'open_num': int(safe_float(row.get(col_open_num))) if col_open_num else 0,
                'industry': safe_str(row.get(col_industry)),
                'pct_20': safe_float(row.get(col_pct20)),
            }

            item['limit_days'] = int(safe_float(row.get(col_zt_days, 0)))
            item['is_zt'] = (item['limit_days'] > 0 and item['today_pct'] > 0) or (item['today_pct'] > 9.8)

            tags = []
            desc = safe_str(row.get(col_desc))
            if desc and len(desc) < 20: tags.append(desc) 

            if item['limit_days'] > 0: tags.append(f"{item['limit_days']}æ¿")

            reason = safe_str(row.get(col_reason))
            if reason: tags.append(reason)

            item['tag_ths'] = "/".join(tags)
            data_map[code] = item

        print(f"   â†³ æˆåŠŸè§£æ {len(data_map)} æ¡æ•°æ®")
        return data_map
    except Exception as e:
        print(f"{Fore.RED}âŒ è¯»å–å¤±è´¥: {e}")
        return {}


def find_previous_ths_file(current_date_int):
    """
    å¯»æ‰¾æ¯” current_date_int å°çš„æœ€è¿‘ä¸€ä¸ªæ—¥æœŸçš„æ–‡ä»¶
    """
    if not os.path.exists(THS_DIR): return None
    
    files = os.listdir(THS_DIR)
    candidates = []
    
    for f in files:
        if f.startswith("Table") and f.endswith(".txt"):
            full_path = os.path.join(THS_DIR, f)
            date_match = re.search(r'[-_]?(20\d{6})', f)
            if date_match:
                d_int = int(date_match.group(1))
                if d_int < current_date_int:
                    candidates.append({'path': full_path, 'date': d_int})
    
    if not candidates: return None
    
    # Sort descending to get the closest past date
    candidates.sort(key=lambda x: x['date'], reverse=True)
    return candidates[0]['path']



# ================= 2. åŠ è½½é€šä¿¡è¾¾ (ä¿æŒç¨³å®š) =================
def load_tdx_data():
    target_file = find_latest_file(TDX_DIR)
    if not target_file: return {}

    print(f"{Fore.CYAN}ğŸ“‚ [æ›¿è¡¥] åŠ è½½é€šä¿¡è¾¾æ•°æ®: {os.path.basename(target_file)}")
    try:
        # é€šä¿¡è¾¾é€šå¸¸åˆ—å¾ˆæ•´é½ï¼Œä¸éœ€è¦æ­£åˆ™
        if target_file.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(target_file, dtype=str)
        else:
            try:
                df = pd.read_csv(target_file, sep=None, engine='python', encoding='gbk', dtype=str)
            except:
                df = pd.read_csv(target_file, sep=None, engine='python', encoding='utf-8', dtype=str)

        df.columns = [str(c).replace('Z', '').strip() for c in df.columns]
        data_map = {}

        col_code = next((c for c in df.columns if 'ä»£ç ' in c), None)
        col_name = next((c for c in df.columns if 'åç§°' in c), None)
        col_pct = next((c for c in df.columns if 'æ¶¨å¹…' in c), None)
        col_price = next((c for c in df.columns if 'ç°ä»·' in c), None)
        col_amt = next((c for c in df.columns if 'é‡‘é¢' in c), None)
        col_to = next((c for c in df.columns if 'æ¢æ‰‹' in c), None)

        if not col_code: return {}

        for _, row in df.iterrows():
            code = clean_code(row[col_code])
            if len(code) != 6: continue

            item = {
                'source': 'TDX',
                'code': code,
                'name': safe_str(row.get(col_name)),
                'price': safe_float(row.get(col_price)),
                'today_pct': safe_float(row.get(col_pct)),
                'amount': safe_float(row.get(col_amt)),
                'turnover': safe_float(row.get(col_to)),
                'pct_10': 0.0,
                'limit_days': 0,
                'is_zt': False
            }
            if item['today_pct'] > 9.8: item['is_zt'] = True
            data_map[code] = item
        return data_map
    except:
        return {}


# ================= 3. API å…œåº• =================
def fetch_akshare_ladder():
    print(f"{Fore.MAGENTA}ğŸŒ [å…œåº•] æ­£åœ¨è”ç½‘æ ¸å¯¹è¿æ¿æ¢¯é˜Ÿ (AkShare)...")
    ladder_map = {}
    try:
        from datetime import datetime
        today = datetime.now().strftime("%Y%m%d")
        df_zt = ak.stock_zt_pool_em(date=today)
        if not df_zt.empty:
            for _, row in df_zt.iterrows():
                code = row['ä»£ç ']
                days = int(row['è¿æ¿æ•°'])
                reason = safe_str(row.get('æ¶¨åœåŸå› ç±»åˆ«'))
                tag = f"{days}æ¿"
                if days == 1 and row['é¦–æ¬¡å°æ¿æ—¶é—´'] == row['æœ€åå°æ¿æ—¶é—´']: tag = "é¦–æ¿/ç¡¬"
                ladder_map[code] = {'limit_days': days, 'tag_api': f"{tag}/{reason}", 'is_zt': True}

        df_zb = ak.stock_zt_pool_zbgc_em(date=today)
        if not df_zb.empty:
            for _, row in df_zb.iterrows():
                ladder_map[row['ä»£ç ']] = {'limit_days': 0, 'tag_api': "ç‚¸æ¿", 'is_zt': False}
    except Exception as e:
        print(f"{Fore.YELLOW}âš ï¸ è”ç½‘å¤±è´¥: {e}")
    return ladder_map


# ================= ä¸»å…¥å£ =================
def get_merged_data():
    map_ths = load_ths_data()
    map_tdx = load_tdx_data()
    map_api = fetch_akshare_ladder()

    all_codes = set(map_ths.keys()) | set(map_tdx.keys())
    if not all_codes and map_api: all_codes = set(map_api.keys())

    final_list = []
    for code in all_codes:
        item = {}
        if code in map_ths:
            item = map_ths[code]
        elif code in map_tdx:
            item = map_tdx[code]
        elif code in map_api:
            info = map_api[code]
            item = {'code': code, 'name': 'API', 'today_pct': 10.0, 'amount': 0,
                    'limit_days': info['limit_days'], 'tag': info['tag_api'], 'is_zt': info['is_zt']}

        if not item: continue

        if 'sina_code' not in item:
            p = "sh" if code.startswith(('6', '9')) else "sz"
            item['sina_code'] = f"{p}{code}"

        if item.get('limit_days', 0) == 0 and code in map_api:
            item['limit_days'] = map_api[code]['limit_days']
            item['is_zt'] = True
            if not item.get('tag_ths'): item['tag'] = map_api[code]['tag_api']

        if code in map_api and not map_api[code]['is_zt']:
            item['tag_extra'] = "ç‚¸æ¿"

        final_tag = item.get('tag_ths', '')
        if not final_tag:
            t = []
            if item.get('tag_extra'): t.append(item['tag_extra'])
            if item.get('limit_days', 0) > 0:
                t.append(f"{item['limit_days']}æ¿")
            elif item['today_pct'] > 9.8:
                t.append("é¦–æ¿")
            final_tag = "/".join(t)

        if item.get('tag_extra') == 'ç‚¸æ¿' and 'ç‚¸æ¿' not in final_tag:
            final_tag = f"ç‚¸æ¿/{final_tag}"

        item['tag'] = final_tag
        final_list.append(item)

    print(f"{Fore.GREEN}âœ… æ•°æ®åˆå¹¶å®Œæ¯•ï¼Œå…± {len(final_list)} åªæ ‡çš„")
    return final_list


# ================= 4. ä¸ºç›‘æ§ç³»ç»Ÿæä¾›ç‰¹å®šæ ¼å¼ =================
def load_history_map():
    """
    ä¸“é—¨ä¸º call_auction_screener.py æä¾›æ•°æ®
    è¿”å›æ ¼å¼: {code: {'yest_amt': float, 'circ_mv': float, 'yest_pct': float, 'boards': int}}
    """
    # 1. ä¼˜å…ˆåŠ è½½åŒèŠ±é¡ºæ•°æ®
    data_map = load_ths_data()
    
    # 2. å¦‚æœç¼ºå°‘åŒèŠ±é¡ºï¼Œå°è¯•ç”¨é€šä¿¡è¾¾è¡¥å…¨ (æš‚ç•¥ï¼Œå› ä¸ºåŒèŠ±é¡ºé€šå¸¸æœ€å…¨)
    
    history_map = {}
    zero_turnover_count = 0
    
    for code, item in data_map.items():
        try:
            amt = item.get('amount', 0.0)
            mv = 0.0 # MVP: åŒèŠ±é¡ºå¯¼å‡ºé‡Œé€šå¸¸æ²¡æœ‰ç›´æ¥çš„æµé€šå¸‚å€¼åˆ—ï¼Œæˆ–è€…åˆ—åä¸å›ºå®š
            # å¦‚æœ item ä¸­æ²¡æœ‰å¸‚å€¼ï¼Œæš‚æ—¶ç»™ 0ï¼Œç›‘æ§è„šæœ¬ä¼šå¤„ç†
            # å®é™…ä¸Š load_ths_dataè§£ææ—¶ä¹Ÿæ²¡æœ‰ä¸“é—¨è§£æå¸‚å€¼åˆ—ï¼Œéœ€è¦æ·»åŠ 
            
            # é‡æ–°æ£€æŸ¥ load_ths_data æ˜¯å¦è§£æäº†å¸‚å€¼
            # å½“å‰ load_ths_data ç¡®å®æ²¡è§£æ 'æµé€šå¸‚å€¼'ï¼Œæˆ‘ä»¬éœ€è¦å¢å¼º load_ths_data
            pass 
        except:
            pass
            
    # ç”±äº load_ths_data éœ€è¦å¢å¼ºï¼Œæˆ‘ä»¬ç›´æ¥åœ¨è¿™é‡Œé‡æ–°å®ç°ä¸€ä¸ªé’ˆå¯¹æ€§çš„å¢å¼ºç‰ˆåŠ è½½ï¼Œ
    # æˆ–è€…ä¿®æ”¹ load_ths_data è®©å…¶è¿”å›æ›´å¤šå­—æ®µã€‚
    # è€ƒè™‘åˆ° load_ths_data è¢« pool_generator ä½¿ç”¨ï¼Œä¿®æ”¹å®ƒæ›´åˆç†ã€‚
    pass

# é‡å†™ load_ths_data ä»¥æ”¯æŒæ›´å¤šå­—æ®µ (å¦‚æµé€šå¸‚å€¼)
def load_ths_data_enhanced():
    # å¤ç”¨æ–‡ä»¶æŸ¥æ‰¾é€»è¾‘
    if not os.path.exists(THS_DIR): return {}
    
    # ... (find file logic duplicated or reused) ...
    # ä¸ºäº†é¿å…é‡å¤ä»£ç ï¼Œå»ºè®®æŠŠ find_file é€»è¾‘æå–ï¼Œä½†è¿™é‡Œä¸ºäº†ä¸åŠ¨å¤ªå¤šç»“æ„ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨ enhance logic
    
    # è°ƒç”¨åŸæœ‰çš„æ–‡ä»¶æŸ¥æ‰¾é€»è¾‘ (è¿™æ˜¯ç§æœ‰çš„ logic inside load_ths_data, we should extract it or copy it)
    # Let's copy the find logic for now to be safe and independent
    files = os.listdir(THS_DIR)
    candidates = []
    for f in files:
        if f.startswith("Table") and f.endswith(".txt"):
            full_path = os.path.join(THS_DIR, f)
            date_match = re.search(r'[-_]?(20\d{6})', f)
            date_int = int(date_match.group(1)) if date_match else 0
            if f == "Table.txt":
                 candidates.append({'path': full_path, 'date': 0, 'mtime': os.path.getmtime(full_path)})
            else:
                 candidates.append({'path': full_path, 'date': date_int, 'mtime': 0})
    
    target_file = None
    if candidates:
        dated = [c for c in candidates if c['date'] > 0]
        if dated:
            dated.sort(key=lambda x: x['date'], reverse=True)
            target_file = dated[0]['path']
        else:
            candidates.sort(key=lambda x: x['mtime'], reverse=True)
            target_file = candidates[0]['path']
            
    if not target_file: return {}

    print(f"{Fore.BLUE}ğŸ“‚ [Data] åŠ è½½åŒèŠ±é¡ºæ•°æ®: {os.path.basename(target_file)}")
    
    # Robust read
    df = None
    encodings = ['gbk', 'utf-8', 'utf-16']
    for enc in encodings:
        try:
            # use header=0 usually
            df = pd.read_csv(target_file, sep=r'\t+', engine='python', encoding=enc, dtype=str)
            # Check if columns look right
            if any('ä»£ç ' in c for c in df.columns):
                break
        except:
            continue
            
    if df is None:
        print(f"{Fore.RED}âŒ è¯»å–å¤±è´¥ï¼Œå°è¯•äº† {encodings} å‡æ— æ³•è§£æ")
        return {}
        
    df.columns = [c.strip() for c in df.columns]
    
    # Mapping
    col_code = next((c for c in df.columns if 'ä»£ç ' in c), None)
    col_amt = next((c for c in df.columns if 'æˆäº¤é¢' in c), None)
    col_mv = next((c for c in df.columns if 'æµé€šå¸‚å€¼' in c), None)
    col_pct = next((c for c in df.columns if 'æ¶¨å¹…' in c and 'ç«ä»·' not in c and '10' not in c), None)
    col_auc_amt = next((c for c in df.columns if 'æ—©ç›˜ç«ä»·é‡‘é¢' in c or 'ç«ä»·é‡‘é¢' in c), None) # Try to find bid amount
    
    # è¿æ¿æå–
    col_zt = next((c for c in df.columns if 'è¿æ¿' in c or 'å‡ å¤©å‡ æ¿' in c), None)

    if not col_code or not col_amt:
        print(f"{Fore.RED}âŒ å…³é”®åˆ—ç¼ºå¤± (ä»£ç /æˆäº¤é¢)")
        return {}
        
    res_map = {}
    cnt_zero = 0
    
    for _, row in df.iterrows():
        try:
            code = clean_code(row[col_code])
            if len(code) != 6: continue
            
            amt = safe_float(row.get(col_amt))
            mv = safe_float(row.get(col_mv))
            pct = safe_float(row.get(col_pct))
            
            boards = 0
            if col_zt:
                b_str = str(row.get(col_zt, ''))
                # æå–æ•°å­—
                nums = re.findall(r'\d+', b_str)
                if nums: boards = int(nums[-1]) # å–æœ€åä¸€ä¸ªæ•°å­— usually "3å¤©2æ¿" -> 2
            
            auc_amt = 0.0
            if col_auc_amt:
                auc_amt = safe_float(row.get(col_auc_amt))
            
            if amt <= 0: cnt_zero += 1
            
            res_map[code] = {
                'yest_amt': amt,
                'circ_mv': mv,
                'yest_pct': pct,
                'boards': boards,
                'yest_bid_amt': auc_amt # Yesterday's Bid Amount
            }
        except:
            continue
            
    if cnt_zero > 0:
        print(f"   âš ï¸ å…¶ä¸­ {cnt_zero} åªæ ‡çš„æ— æˆäº¤é¢æ•°æ®")
        
    return res_map

load_history_map = load_ths_data_enhanced