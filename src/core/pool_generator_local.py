# ==============================================================================
# ğŸ“Œ 1-L. Fä½¬/Boä½¬ ç¦»çº¿å¤ç›˜ç”Ÿæˆå™¨ (Local Smart Version) - v1.6 æ™ºèƒ½è¡¨å¤´ç‰ˆ
# åŠŸèƒ½ï¼šè‡ªåŠ¨è¯†åˆ«å¸¦æ—¥æœŸçš„åŒèŠ±é¡ºè¡¨å¤´ï¼ŒæŠ“å–æœ€æ–°æ•°æ®ï¼Œä¸¥æ ¼å¤åˆ»APIé€»è¾‘
# ==============================================================================

import pandas as pd
import os
import sys
import re
import shutil
from datetime import datetime
from colorama import init, Fore

# é€‚é… Windows æ§åˆ¶å°
if sys.platform == 'win32':
    import io

    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

init(autoreset=True)

# ================= 1. è·¯å¾„ä¸é…ç½® =================

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))

# è¾“å…¥æ–‡ä»¶
HOLDINGS_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'holdings.txt')
THS_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'ths_clipboard.txt')
F_LAO_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'f_lao_list.txt')
LOCAL_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'input', 'ths_all_data.txt')

# è¾“å‡ºæ–‡ä»¶
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'data', 'output')
ARCHIVE_DIR = os.path.join(OUTPUT_DIR, 'archive')

# --- ç­–ç•¥å‚æ•° ---
CORE_KEYWORDS = [
    'æœºå™¨äºº', 'èˆªå¤©', 'å†›å·¥', 'å«æ˜Ÿ', 'ä½ç©º',
    'AI', 'äººå·¥æ™ºèƒ½', 'æ™ºèƒ½ä½“', 'ç®—åŠ›', 'CPO', 'å­˜å‚¨',
    'æ¶ˆè´¹ç”µå­', 'åä¸º', 'ä¿¡åˆ›', 'æ•°å­—è´§å¸', 'æ•°æ®è¦ç´ ',
    'æ–‡åŒ–ä¼ åª’', 'çŸ­å‰§', 'å¤šæ¨¡æ€', 'çººç»‡', 'å¹¶è´­é‡ç»„', 'å›ºæ€ç”µæ± ', 'è‡ªåŠ¨é©¾é©¶'
]

HOT_CONCEPTS = [
    ('äººå½¢æœºå™¨äºº', 'concept'),
    ('å•†ä¸šèˆªå¤©', 'concept'),
    ('AIæ™ºèƒ½ä½“', 'concept'),
    ('æ¶ˆè´¹ç”µå­', 'industry'),
    ('ä½ç©ºç»æµ', 'concept'),
    ('æ•°å­—è´§å¸', 'concept'),
    ('æ–‡åŒ–ä¼ åª’', 'industry'),
]

HOLDING_STRATEGIES = {
    '603667': ('æŒä»“/äº”æ´²(æœºå™¨äºº/èˆªå¤©)', ''),
    '300115': ('æŒä»“/é•¿ç›ˆ(æ¶ˆç”µä¸­å†›)', 'sz002475'),
    '001231': ('æŒä»“/å†œå¿ƒ(å†œä¸š)', ''),
}

LINK_DRAGON_MAP = {
    '002009': '002931',
}

# å…¨å±€æ•°æ®ç¼“å­˜
ALL_LOCAL_DATA = {}


# ================= 2. æ™ºèƒ½è§£ææ ¸å¿ƒ =================

def parse_val(v):
    """æ•°å€¼æ¸…æ´—å·¥å…·"""
    if not v or '--' in str(v): return 0.0
    v = str(v).replace(',', '')
    if 'äº¿' in v: v = v.replace('äº¿', '*100000000')
    if 'ä¸‡' in v: v = v.replace('ä¸‡', '*10000')
    if '%' in v: v = v.replace('%', '*0.01')
    try:
        return float(eval(v))
    except:
        return 0.0


def resolve_best_column(headers, keywords):
    """
    åœ¨è¡¨å¤´ä¸­æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„åˆ—ã€‚
    å¦‚æœæœ‰å¤šåˆ—å‘½ä¸­ï¼ˆå¦‚'æˆäº¤é¢[2025]'å’Œ'æˆäº¤é¢[2026]'ï¼‰ï¼Œå–æ—¥æœŸæœ€æ–°çš„é‚£ä¸€åˆ—ã€‚
    è¿”å›: æœ€ä½³åˆ—çš„ç´¢å¼• (int) æˆ– -1 (æœªæ‰¾åˆ°)
    """
    candidates = []
    for idx, h in enumerate(headers):
        for kw in keywords:
            if kw in h:
                # å°è¯•æå–æ—¥æœŸ
                date_match = re.search(r'(\d{8})', h)
                date_val = int(date_match.group(1)) if date_match else 99999999  # æ— æ—¥æœŸè§†ä¸ºæ°¸ä¹…/æœ€æ–°
                candidates.append((idx, h, date_val))
                break

    if not candidates:
        return -1

    # æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼Œå–ç¬¬ä¸€ä¸ª
    candidates.sort(key=lambda x: x[2], reverse=True)
    best = candidates[0]
    # print(f"   â„¹ï¸ åˆ—åŒ¹é…: '{keywords[0]}' -> ä½¿ç”¨ '{best[1]}'") # è°ƒè¯•ç”¨
    return best[0]


def load_local_ths_data():
    global ALL_LOCAL_DATA
    if not os.path.exists(LOCAL_DATA_PATH):
        print(f"{Fore.RED}âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {LOCAL_DATA_PATH}")
        return False

    print(f"{Fore.MAGENTA}ğŸ“‚ æ­£åœ¨è§£ææœ¬åœ°æ•°æ® (Smart Mode v1.6)...{Fore.RESET}")
    lines = []
    for enc in ['utf-8', 'gbk', 'gb18030', 'utf-16']:
        try:
            with open(LOCAL_DATA_PATH, 'r', encoding=enc) as f:
                lines = f.readlines()
            break
        except:
            continue

    lines = [L for L in lines if L.strip()]
    if not lines:
        print(f"{Fore.RED}âŒ æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–{Fore.RESET}")
        return False

    if len(lines) < 100:
        print(f"{Fore.YELLOW}âš ï¸ è­¦å‘Š: æ•°æ®è¡Œæ•°ä»… {len(lines)} è¡Œï¼Œè¯·ç¡®è®¤æ˜¯å¦å¯¼å‡ºäº†ã€æ‰€æœ‰æ•°æ®ã€‘ï¼{Fore.RESET}")

    headers = re.split(r'\t+|\s{2,}', lines[0].strip())

    # --- æ™ºèƒ½æ˜ å°„è¡¨å¤´ ---
    col_map = {}

    # åŸºç¡€åˆ—
    col_map['code'] = resolve_best_column(headers, ['ä»£ç '])
    col_map['name'] = resolve_best_column(headers, ['åç§°'])
    col_map['price'] = resolve_best_column(headers, ['ç°ä»·'])
    col_map['pct'] = resolve_best_column(headers, ['æ¶¨å¹…'])
    col_map['turnover'] = resolve_best_column(headers, ['æ¢æ‰‹'])
    col_map['pct_10'] = resolve_best_column(headers, ['10æ—¥æ¶¨å¹…'])
    col_map['prev_close'] = resolve_best_column(headers, ['æ˜¨æ”¶'])
    col_map['open'] = resolve_best_column(headers, ['ä»Šå¼€'])
    col_map['high'] = resolve_best_column(headers, ['æœ€é«˜'])

    # å…³é”®åŠ¨æ€åˆ— (å¸¦æ—¥æœŸ)
    col_map['amount'] = resolve_best_column(headers, ['æˆäº¤é¢'])
    col_map['vol'] = resolve_best_column(headers, ['æˆäº¤é‡', 'æ€»æ‰‹'])
    col_map['limit_days'] = resolve_best_column(headers, ['è¿æ¿', 'è¿ç»­æ¶¨åœ'])
    col_map['open_num'] = resolve_best_column(headers, ['å¼€æ¿', 'ç‚¸æ¿'])
    col_map['concepts'] = resolve_best_column(headers, ['æ¦‚å¿µ', 'è¡Œä¸š', 'æ¶¨åœåŸå› '])

    # æ£€æŸ¥ç¼ºå¤±
    missing = [k for k, v in col_map.items() if v == -1 and k in ['limit_days', 'amount', 'open_num']]
    if missing:
        print(f"{Fore.RED}âŒ ä¾ç„¶ç¼ºå°‘å…³é”®åˆ—: {missing}ã€‚è¯·æ£€æŸ¥è¡¨å¤´è®¾ç½®ï¼{Fore.RESET}")
        # è¿™é‡Œä¸returnï¼Œå°è¯•ç¡¬è·‘

    count = 0
    for line in lines[1:]:
        parts = re.split(r'\t+|\s{2,}', line.strip())
        if len(parts) < 5: continue

        # å®‰å…¨å–å€¼ helper
        def get_val(key, default=0):
            idx = col_map.get(key, -1)
            if idx != -1 and idx < len(parts): return parts[idx]
            return default

        raw_code = get_val('code', '000000')
        code = re.sub(r'\D', '', raw_code)
        if len(code) != 6: continue

        try:
            price = parse_val(get_val('price'))
            pct = parse_val(get_val('pct'))
            if abs(pct) < 0.3 and pct != 0: pct *= 100

            # å…³é”®é€»è¾‘å­—æ®µ
            limit_days_str = get_val('limit_days', '0')
            limit_days = int(parse_val(limit_days_str))

            open_num_str = get_val('open_num', '0')
            open_num = int(parse_val(open_num_str))

            amount = parse_val(get_val('amount'))

            # æ¦‚å¿µå¯èƒ½æ˜¯å­—ç¬¦ä¸²
            concept_str = str(get_val('concepts', ''))

            # å…œåº•ï¼šå¦‚æœæ²¡æ‰¾åˆ°è¿æ¿åˆ—ï¼Œå°è¯•é€šè¿‡æ¶¨å¹…æ¨æ–­é¦–æ¿
            high = parse_val(get_val('high'))
            is_zt_approx = (pct > 9.8) and (high == price)

            data = {
                'code': code,
                'name': str(get_val('name', 'æœªçŸ¥')),
                'price': price,
                'today_pct': pct,
                'amount': amount,
                'vol': parse_val(get_val('vol')),
                'turnover': parse_val(get_val('turnover')),
                'pct_10': parse_val(get_val('pct_10')),
                'limit_days': limit_days,
                'open_num': open_num,
                'concept_str': concept_str,
                'is_zt_approx': is_zt_approx,
                'prev_close': parse_val(get_val('prev_close')),
                'open_price': parse_val(get_val('open')),
                'vol_ratio': 1.0,
                'vol_prev': 0.0
            }

            # è¡¥é½è®¡ç®—
            if data['prev_close'] == 0: data['prev_close'] = price
            if data['open_price'] == 0: data['open_price'] = price

            if data['prev_close'] > 0:
                data['open_pct'] = round((data['open_price'] - data['prev_close']) / data['prev_close'] * 100, 2)

            # ç®€å•çš„æ˜¨é‡ä¼°ç®— (å› ä¸ºæœ¬åœ°å¯èƒ½ç¼ºæ˜¨é‡åˆ—)
            data['vol_prev'] = data['vol']  # æš‚ä¸”ç›¸ç­‰

            ALL_LOCAL_DATA[code] = data
            count += 1
        except Exception as e:
            continue

    print(f"   â†³ æˆåŠŸåŠ è½½ {count} æ¡æ•°æ®")
    return count > 0


# ================= 3. é€šç”¨è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) =================

def format_sina(code):
    if code.startswith('6'): return f"sh{code}"
    if code.startswith('8') or code.startswith('4'): return f"bj{code}"
    return f"sz{code}"


def get_link_dragon(code):
    if code in HOLDING_STRATEGIES:
        dragon = HOLDING_STRATEGIES[code][1]
        if dragon: return dragon
    dragon = LINK_DRAGON_MAP.get(code, '')
    if dragon: return dragon if dragon.startswith('s') else format_sina(dragon)
    return ''


def get_core_concepts(code, name):
    if code not in ALL_LOCAL_DATA: return ""
    raw = ALL_LOCAL_DATA[code]['concept_str']
    matched = set()
    for key in CORE_KEYWORDS:
        if key in raw: matched.add(key)
    return "/".join(list(matched))


def get_market_data(code):
    if code in ALL_LOCAL_DATA:
        d = ALL_LOCAL_DATA[code]
        return {
            'vol': d['vol'], 'amount': d['amount'], 'vol_prev': d['vol_prev'],
            'vol_ratio': d['vol_ratio'], 'pct_10': d['pct_10'], 'price': d['price'],
            'open_pct': d['open_pct'], 'today_pct': d['today_pct'], 'turnover': d['turnover'],
            'low': d['price'] * 0.9, 'high': d['price'] * 1.1, 'prev_close': d['prev_close']
        }
    return None


def check_special_shape(m_data):
    tags = []
    if m_data:
        if m_data['today_pct'] > 9.0 and m_data['open_pct'] < -5.0: tags.append("ğŸ”¥é•¿è…¿/ç–‘ä¼¼åœ°å¤©")
        if m_data['today_pct'] > 14.0: tags.append("ğŸ”¥20cm")
        amt_yi = m_data['amount'] / 100000000
        if amt_yi > 20.0:
            tags.append("ğŸ’°å¤§æˆ˜åœº")
        elif amt_yi < 0.5:
            tags.append("âš ï¸æµåŠ¨æ€§å·®")
    return tags


def load_manual_lists():
    combined = {}
    if os.path.exists(THS_PATH):
        try:
            with open(THS_PATH, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except:
            try:
                with open(THS_PATH, 'r', encoding='gbk') as f:
                    lines = f.readlines()
            except:
                lines = []
        for line in lines:
            line = line.strip()
            if not line or "ä»£ç " in line: continue
            parts = re.split(r'\s+', line)
            if len(parts) >= 2:
                code = parts[0].replace("SZ", "").replace("SH", "")
                if code.isdigit(): combined[code] = f"åŒèŠ±é¡º/{parts[1]}"

    if os.path.exists(HOLDINGS_PATH):
        try:
            with open(HOLDINGS_PATH, 'r', encoding='utf-8') as f:
                for line in f:
                    if "ä»£ç " in line: continue
                    parts = re.split(r'\s+', line.strip())
                    if len(parts) >= 2: combined[parts[0]] = f"æŒä»“/{parts[1]}"
        except:
            pass

    if os.path.exists(F_LAO_PATH):
        try:
            with open(F_LAO_PATH, 'r', encoding='utf-8') as f:
                for line in f:
                    if not line.strip() or line.startswith('#'): continue
                    parts = re.split(r'\s+', line.strip(), maxsplit=1)
                    if len(parts) >= 2: combined[parts[0]] = parts[1]
        except:
            pass
    return combined


# ================= 4. ä¸»é€»è¾‘ =================

def generate_csv():
    if not load_local_ths_data(): return

    os.makedirs(ARCHIVE_DIR, exist_ok=True)
    strategy_rows = []
    seen_codes = set()

    def add_item(code, name, base_tag):
        if code in seen_codes or code not in ALL_LOCAL_DATA: return
        m_data = get_market_data(code)
        extra = get_core_concepts(code, name)
        specials = check_special_shape(m_data)
        tag_list = [base_tag]
        if extra: tag_list.append(extra)
        tag_list.extend(specials)
        final_tag = "/".join(tag_list)

        strategy_rows.append({
            'code': code, 'name': name, 'tag': final_tag,
            'link_dragon': get_link_dragon(code),
            'vol': int(m_data['vol']), 'amount': m_data['amount'],
            'vol_prev': int(m_data['vol_prev']), 'vol_ratio': m_data.get('vol_ratio', 0),
            'pct_10': m_data['pct_10'], 'price': m_data['price'],
            'open_pct': m_data['open_pct'], 'today_pct': m_data['today_pct'],
            'turnover': m_data['turnover']
        })
        seen_codes.add(code)
        print(f"å…¥æ± : {name:<8} ({final_tag})")

    # [1] æ¶¨åœ
    print(f"\n{Fore.YELLOW}[1/5] ç­›é€‰æ¶¨åœ...{Fore.RESET}")
    for code, d in ALL_LOCAL_DATA.items():
        if d['limit_days'] > 0:
            tag = f"{d['limit_days']}æ¿"
            if d['open_num'] > 0:
                tag += f"/å›å°(ç‚¸{d['open_num']})"
            else:
                tag += "/ç¡¬æ¿"
            add_item(code, d['name'], tag)
        elif d['is_zt_approx']:
            add_item(code, d['name'], "1æ¿/é¦–æ¿")

    # [2] ç‚¸æ¿
    print(f"\n{Fore.YELLOW}[2/5] ç­›é€‰ç‚¸æ¿...{Fore.RESET}")
    for code, d in ALL_LOCAL_DATA.items():
        if d['open_num'] > 0 and d['limit_days'] == 0 and d['today_pct'] > -8.0:
            add_item(code, d['name'], "ç‚¸æ¿/ååŒ…é¢„æœŸ")

    # [3] è·Œåœ
    print(f"\n{Fore.YELLOW}[3/5] ç­›é€‰è·Œåœ...{Fore.RESET}")
    for code, d in ALL_LOCAL_DATA.items():
        if d['today_pct'] < -9.8:
            add_item(code, d['name'], "è·Œåœ/åšå¼ˆä¿®å¤")

    # [4] ä¸­å†›
    print(f"\n{Fore.YELLOW}[4/5] ç­›é€‰æ¿å—ä¸­å†›...{Fore.RESET}")
    for concept_kw, _ in HOT_CONCEPTS:
        candidates = [d for code, d in ALL_LOCAL_DATA.items() if concept_kw in d['concept_str']]
        candidates.sort(key=lambda x: x['amount'], reverse=True)
        for d in candidates[:2]:
            tag_s = f"{concept_kw}ä¸­å†›"
            if d['code'] in seen_codes:
                # æ›´æ–°å·²æœ‰
                for row in strategy_rows:
                    if row['code'] == d['code'] and tag_s not in row['tag']:
                        row['tag'] += f"/{tag_s}"
            else:
                add_item(d['code'], d['name'], tag_s)

    # [5] å…³æ³¨åˆ—è¡¨
    print(f"\n{Fore.YELLOW}[5/5] æ³¨å…¥å…³æ³¨åˆ—è¡¨...{Fore.RESET}")
    manual = load_manual_lists()
    for code, tag in manual.items():
        if code in ALL_LOCAL_DATA:
            if code in seen_codes:
                for row in strategy_rows:
                    if row['code'] == code:
                        clean = tag.split('/')[1] if '/' in tag else tag
                        if clean not in row['tag']: row['tag'] = f"{clean}/{row['tag']}"
            else:
                add_item(code, ALL_LOCAL_DATA[code]['name'], tag)

    # å¯¼å‡º
    if strategy_rows:
        df = pd.DataFrame(strategy_rows)
        df['sina_code'] = df['code'].apply(format_sina)
        df.sort_values(by='amount', ascending=False, inplace=True)
        cols = ['sina_code', 'name', 'tag', 'amount', 'today_pct', 'turnover', 'open_pct', 'price', 'pct_10',
                'link_dragon', 'vol', 'vol_prev', 'code']
        df = df.reindex(columns=cols)

        date_str = datetime.now().strftime("%Y%m%d")
        save_path = os.path.join(ARCHIVE_DIR, f'strategy_pool_LOCAL_{date_str}.csv')
        df.to_csv(save_path, index=False, encoding='utf-8-sig')
        shutil.copyfile(save_path, os.path.join(OUTPUT_DIR, 'strategy_pool.csv'))
        print(f"\n{Fore.GREEN}âœ… æˆåŠŸç”Ÿæˆ {len(df)} åªæ ‡çš„ï¼{Fore.RESET}")
    else:
        print(f"{Fore.RED}âŒ ç»“æœä¸ºç©ºã€‚è¯·æ£€æŸ¥æ•°æ®æºæ˜¯å¦åŒ…å«æ¶¨åœè‚¡ã€‚{Fore.RESET}")


if __name__ == "__main__":
    generate_csv()